{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccfb2161",
   "metadata": {},
   "source": [
    "## Glazing Branches Order Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb25f57d",
   "metadata": {},
   "source": [
    "### Importing Required  Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00d1ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygsheets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "sns.set(style='ticks', palette='RdBu')\n",
    "#sns.set(style='ticks', palette='Set2')\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pytz\n",
    "import businesstimedelta\n",
    "import holidays as pyholidays\n",
    "%matplotlib inline\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "#pip3 install --upgrade pip\n",
    "#pip3 install jupyter\n",
    "\n",
    "today = date.today()\n",
    "last=today-relativedelta(months=4)\n",
    "last=str(last)\n",
    "today=str(today)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d613e1",
   "metadata": {},
   "source": [
    "### Login to the APA DW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ad2e062",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Login\n",
    "url = \"http://10.10.15.222/api/v1/auth/login\"\n",
    "\n",
    "payload = json.dumps({\n",
    " \"email\": \"derick@optica.africa\",\n",
    "  \"password\":os.environ.get(\"API_PASSWORD\")\n",
    "})\n",
    "\n",
    "headers = {\n",
    " 'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "result = response.json()\n",
    "\n",
    "access_token = result[\"access_token\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23587dbb",
   "metadata": {},
   "source": [
    "###  Pulling Required Data Sets--OrderScreenc1 and OrderScreen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d472fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Screen log/Workload/Order Screen Child\n",
    "#######################################################################################################\n",
    "\n",
    "url = \"http://10.10.15.222/api/v1/fetch/OrderScreenc1\"\n",
    "today = date.today()\n",
    "last=today-relativedelta(months=3)\n",
    "last=str(last)\n",
    "today=str(today)\n",
    "\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"entity\": \"OrderScreenc1\",\n",
    "  \"filter_column\": \"Date\",\n",
    "  \"start\":last,\n",
    "  \"end\": today\n",
    "})\n",
    "\n",
    "\n",
    "headers = {'Authorization': f\"Bearer {access_token}\",'Content-Type': 'application/json'}\n",
    "\n",
    "response = requests.request(\"PUT\", url, headers=headers, data=payload)\n",
    "\n",
    "result = response.json()\n",
    "import pandas as pd\n",
    "df= pd.DataFrame(result[\"data\"])\n",
    "\n",
    "Workload=df[[\"odsc_createdby\",\"Date\",\"Time\",\"Status\",\"DocEntry\",\"odsc_remarks\"]].rename(\n",
    "      columns={\"odsc_createdby\":\"Created User\",\"odsc_remarks\":\"TO_VARCHAR(U_VSPRMKS)\"})\n",
    "\n",
    "Workload[\"Date\"]=pd.to_datetime(Workload[\"Date\"]).dt.date\n",
    "Workload[\"Time\"]=pd.to_datetime(Workload[\"Time\"],format= '%H%M').dt.time\n",
    "MasterData=Workload\n",
    "MasterData[\"TimeStamp\"] = pd.to_datetime(MasterData.Date.astype(str) + ' ' + MasterData.Time.astype(str), format=\"%Y%m%d %H:%M:%S\",errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "159ed067",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Orders/Order Screen\n",
    "#######################################################################################################\n",
    "today = date.today()\n",
    "last=today-relativedelta(months=6)\n",
    "last=str(last)\n",
    "today=str(today)\n",
    "url = \"http://10.10.15.222/api/v1/fetch/OrderScreen\"\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"entity\": \"OrderScreen\",\n",
    "  \"filter_column\": \"Creation_Time\",\n",
    "  \"start\": last,\n",
    "  \"end\": today\n",
    "})\n",
    "\n",
    "\n",
    "headers = {'Authorization': f\"Bearer {access_token}\",'Content-Type': 'application/json'}\n",
    "\n",
    "response = requests.request(\"PUT\", url, headers=headers, data=payload)\n",
    "\n",
    "result = response.json()\n",
    "import pandas as pd\n",
    "df= pd.DataFrame(result[\"data\"])\n",
    "\n",
    "AllOrders =df.rename(columns={\"doc_entry\":\"DocEntry\",\"doc_no\":\"Order No.\",\"ods_creator\":\"Order Creator\",\"cust_code\":\"Customer Code\",\n",
    "                       \"ods_ordertype\":\"Order Type\",\"ods_status\":\"Status\",\"ods_status1\":\"Status1\",\n",
    "                       \"ods_outlet\":\"Outlet\",\"ods_orderno\":\"Sales Order No.\",\"ods_orderprocess_branch\":\"OrderProcess Branch\",\n",
    "                             \"ods_ordercriteriastatus\":\"OrderCriteria\"})\n",
    "\n",
    "\n",
    "AllOrders_data=AllOrders[[\"DocEntry\",\"Order No.\",\"OrderProcess Branch\",\"OrderCriteria\",\"Outlet\",\"ods_repair_branch\",\"ods_preqc_tech\",\"ods_final_qc_tech\",\"Status\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da19e9ad",
   "metadata": {},
   "source": [
    "### Defining/Filtering various statuses Timestamps i.e salesorder created,awaitting for collection,collected etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7bd4a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:5039: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#############################################################################################\n",
    "##Sales Orders\n",
    "salesCreatedStatus=['Sales Order Created','Confirmed by Approvals Team']\n",
    "SalesOrderCreated=MasterData[MasterData.Status.isin(salesCreatedStatus)]\n",
    "SalesOrderCreated=SalesOrderCreated[[\"DocEntry\",\"TimeStamp\"]]\n",
    "SalesOrderCreated.rename(columns={\"TimeStamp\":\"SalesOrderCreated\"},inplace=True)\n",
    "\n",
    "################################################################################################\n",
    "##Awaitting for collection Data\n",
    "\n",
    "AwaittingForCollection=MasterData[MasterData.Status==\"Awaiting for Collection\"]\n",
    "AwaittingForCollection.rename(columns={\"TimeStamp\":\"Awaitting_For_Collection\"},inplace=True)\n",
    "###############################################################################################\n",
    "##Collected\n",
    "Collected=MasterData[MasterData.Status==\"Collected\"]\n",
    "Collected=Collected[[\"DocEntry\",\"TimeStamp\"]]\n",
    "Collected.rename(columns={\"TimeStamp\":\"Collected\"},inplace=True)\n",
    "SalesOrderCreated=pd.merge(SalesOrderCreated,Collected,on=\"DocEntry\",how=\"outer\")\n",
    "########################################Time from Satelite Branch to Glazing Branch##################################################################################\n",
    "##Satelite Branches sending Orders\n",
    "Sending_Status = [\"Printed PF Identifier\",\"Printed Frame Identifier\",\"Printed Repair Identifier\",\"Printed Frame Identifier\",\"Printed Lens Identifier\",\n",
    "          \"Printed PF to Follow Identifier\",\"Printed Frame and Lens Identifier\"]\n",
    "\n",
    "Sending_Orders=MasterData[MasterData.Status.isin(Sending_Status)]\n",
    "Sending_Orders=Sending_Orders[[\"DocEntry\",\"TimeStamp\"]]\n",
    "Sending_Orders.rename(columns={\"TimeStamp\":\"Satelite_Sending\"},inplace=True)\n",
    "##Main Branches Receiving Orders\n",
    "Status_Receiving= [\"Order Printed at Branch\",\"Order Printed\",\"Assigned to Technician at Branch\"]\n",
    "Receiving_Orders=MasterData[MasterData.Status.isin(Status_Receiving)]\n",
    "Receiving_Orders=Receiving_Orders[[\"DocEntry\",\"TimeStamp\"]]\n",
    "Receiving_Orders.rename(columns={\"TimeStamp\":\"Main_Receiving\"},inplace=True)\n",
    "SateliteBranch_Sending_Time=pd.merge(Sending_Orders,Receiving_Orders,on=\"DocEntry\",how=\"outer\")\n",
    "\n",
    "#####################################Time from Glazing Branch to Satellite#####################################################################################\n",
    "Sending_Orders=MasterData[MasterData.Status==\"Fitting Process Completed at Branch\"]\n",
    "Sending_Orders=Sending_Orders[[\"DocEntry\",\"TimeStamp\"]]\n",
    "Sending_Orders.rename(columns={\"TimeStamp\":\"Main_Sending\"},inplace=True)\n",
    "\n",
    "Receiving_Orders=MasterData[MasterData.Status==\"Awaiting for Collection\"]\n",
    "Receiving_Orders=Receiving_Orders[[\"DocEntry\",\"TimeStamp\"]]\n",
    "Receiving_Orders.rename(columns={\"TimeStamp\":\"Satelite_Receiving\"},inplace=True)\n",
    "MainBranch_Sending_Time=pd.merge(Sending_Orders,Receiving_Orders,on=\"DocEntry\",how=\"outer\")\n",
    "\n",
    "\n",
    "Satelite_MainBranch_RiderTimings=pd.merge(SateliteBranch_Sending_Time,MainBranch_Sending_Time,on=\"DocEntry\",how=\"outer\")\n",
    "\n",
    "SalesOrderCreated=pd.merge(SalesOrderCreated,Satelite_MainBranch_RiderTimings,on=\"DocEntry\",how=\"outer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e97a89",
   "metadata": {},
   "source": [
    "### Defining Your Date Range for the Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12b43450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Date Range, starting with 'start date' to 'end date' comma separated 0    2022-03-23\n",
      "1    2022-03-24\n",
      "2    2022-03-25\n",
      "3    2022-03-26\n",
      "4    2022-03-27\n",
      "        ...    \n",
      "85   2022-03-18\n",
      "86   2022-03-19\n",
      "87   2022-03-20\n",
      "88   2022-03-21\n",
      "89   2022-03-22\n",
      "Name: 0, Length: 90, dtype: datetime64[ns]\n",
      "2022-03-21,2022-03-26\n"
     ]
    }
   ],
   "source": [
    "MasterData=Workload\n",
    "unique=MasterData['Date'].unique()\n",
    "unique=pd.DataFrame(unique)\n",
    "unique=pd.to_datetime(unique[0],infer_datetime_format=True)\n",
    "print(f\"Enter Date Range, starting with 'start date' to 'end date' comma separated {unique}\" )\n",
    "From,To =str(input()).split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf70867",
   "metadata": {},
   "source": [
    "### Filtering the Data as per the Defined Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afe9e0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3857814921.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  AwaittingForCollection[\"From\"]=From\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3857814921.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  AwaittingForCollection[\"To\"]=To\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3857814921.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  AwaittingForCollection[\"To\"]= pd.to_datetime(AwaittingForCollection[\"To\"].astype(str), format=\"%Y-%m-%d\",errors=\"coerce\")\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3857814921.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  AwaittingForCollection[\"From\"]= pd.to_datetime(AwaittingForCollection[\"From\"].astype(str), format=\"%Y-%m-%d\",errors=\"coerce\")\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3857814921.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  AwaittingForCollection[\"Comparison\"]= pd.to_datetime(AwaittingForCollection[\"Date\"].astype(str), format=\"%Y-%m-%d\",errors=\"coerce\")\n"
     ]
    }
   ],
   "source": [
    "AwaittingForCollection[\"From\"]=From\n",
    "AwaittingForCollection[\"To\"]=To\n",
    "AwaittingForCollection[\"To\"]= pd.to_datetime(AwaittingForCollection[\"To\"].astype(str), format=\"%Y-%m-%d\",errors=\"coerce\")\n",
    "AwaittingForCollection[\"From\"]= pd.to_datetime(AwaittingForCollection[\"From\"].astype(str), format=\"%Y-%m-%d\",errors=\"coerce\")\n",
    "AwaittingForCollection[\"Comparison\"]= pd.to_datetime(AwaittingForCollection[\"Date\"].astype(str), format=\"%Y-%m-%d\",errors=\"coerce\")\n",
    "\n",
    "AwaittingForCollection =AwaittingForCollection[(AwaittingForCollection[\"Comparison\"] >=AwaittingForCollection[\"From\"]) &\n",
    "                                              (AwaittingForCollection[\"Comparison\"] <=AwaittingForCollection[\"To\"])] \n",
    "\n",
    "AwaittingForCollection=AwaittingForCollection[[\"DocEntry\",\"Awaitting_For_Collection\"]]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e174ae",
   "metadata": {},
   "source": [
    "### Glazing Branches Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc552560",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.merge(AwaittingForCollection,SalesOrderCreated,on=\"DocEntry\",how=\"left\")\n",
    "GlazingBranchesData=pd.merge(AllOrders_data,Workload,on=\"DocEntry\",how=\"right\")\n",
    "FilterStatus=['Fitting Process Completed at Branch','Sent to Packaging']\n",
    "FilterProcessingBranch=['','0LE','0MA','0VE','0DS','HQWS']\n",
    "Criterias=[\"Branch Frame and HQ Lens Glazed at Branch\",\"PF and HQ Lens Glazed at Branch\",\"Surfacing Lens with Branch Frame Glazed at Branch\",\"Surfacing Lens with PF Glazed at Branch\"]\n",
    "GlazingBranchesData=GlazingBranchesData[(~GlazingBranchesData[\"OrderProcess Branch\"].isin(FilterProcessingBranch)) &\n",
    "                                        (GlazingBranchesData[\"Status_y\"].isin(FilterStatus))&\n",
    "                                        (GlazingBranchesData[\"Status_x\"]!='Cancel')&\n",
    "                                        (~GlazingBranchesData[\"OrderCriteria\"].isin(Criterias))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d664b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GlazingBranchesData=pd.merge(GlazingBranchesData,data,on=\"DocEntry\",how=\"inner\")\n",
    "GlazingBranchesData.drop([\"Status_x\",\"Date\",\"Time\",\"Status_y\",\"TO_VARCHAR(U_VSPRMKS)\",\"TimeStamp\",\"ods_repair_branch\",\"ods_preqc_tech\"],\n",
    "                        inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256d7751",
   "metadata": {},
   "source": [
    "### NaKuru and its Satelite Branches \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "197b2e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\workalendar\\core.py:436: UserWarning: Please take note that, due to arbitrary decisions, this Islamic calendar computation may be wrong.\n",
      "  warnings.warn('Please take note that, due to arbitrary decisions, '\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3427328183.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Nakuru_Data[\"Duration\"]=(SalesToAwCollectn_Wkhrs+SalesToAwCollectn_Sathrs)*60\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3427328183.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Nakuru_Data[\"Sales_To_Collected\"]=(SalesToCollectn_Wkhrs+SalesToCollectn_Sathrs)*60\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3427328183.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Nakuru_Data[\"SateliteSendingTime\"]=(SateliteSending_Wkhrs+SateliteSending_Sathrs)*60\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3427328183.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Nakuru_Data[\"SateliteReceivingTime\"]=(SateliteReceiving_Wkhrs+SateliteReceiving_Sathrs)*60\n"
     ]
    }
   ],
   "source": [
    "Nakuru_Branches=[\"NAK\",\"NWE\",\"GOL\"]\n",
    "Nakuru_Data=GlazingBranchesData[GlazingBranchesData[\"OrderProcess Branch\"].isin(Nakuru_Branches)]\n",
    "\n",
    "####Days of the week\n",
    "workday = businesstimedelta.WorkDayRule(start_time=datetime.time(9),end_time=datetime.time(18),working_days=[0,1, 2, 3, 4])\n",
    "vic_holidays = pyholidays.KE()\n",
    "holidays = businesstimedelta.HolidayRule(vic_holidays)\n",
    "from workalendar.africa import Kenya\n",
    "cal = Kenya()\n",
    "hl = cal.holidays()\n",
    "my_dict=dict(hl)\n",
    "vic_holidays=vic_holidays.append(my_dict)\n",
    "businesshrs = businesstimedelta.Rules([workday, holidays])\n",
    "\n",
    "def BusHrs(start, end):\n",
    "    if end>=start:\n",
    "        return businesshrs.difference(start,end).hours+float(businesshrs.difference(start,end).seconds)/float(3600)\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "SalesToAwCollectn_Wkhrs=Nakuru_Data.apply(lambda row: BusHrs(row[\"SalesOrderCreated\"], row['Awaitting_For_Collection']), axis=1)\n",
    "SalesToCollectn_Wkhrs=Nakuru_Data.apply(lambda row: BusHrs(row[\"SalesOrderCreated\"], row['Collected']), axis=1)\n",
    "SateliteSending_Wkhrs=Nakuru_Data.apply(lambda row: BusHrs(row[\"Satelite_Sending\"], row['Main_Receiving']), axis=1)\n",
    "SateliteReceiving_Wkhrs=Nakuru_Data.apply(lambda row: BusHrs(row[\"Main_Sending\"], row['Awaitting_For_Collection']), axis=1)\n",
    "\n",
    "####Weekends\n",
    "# Define a working weekend day(Saturday)\n",
    "\n",
    "Saturday = businesstimedelta.WorkDayRule(start_time=datetime.time(9),end_time=datetime.time(16),working_days=[5])\n",
    "\n",
    "businesshrs = businesstimedelta.Rules([Saturday, holidays])\n",
    "\n",
    "def SatHrs(start, end):\n",
    "    if end>=start:\n",
    "         return businesshrs.difference(start,end).hours+float(businesshrs.difference(start,end).seconds)/float(3600)\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "    \n",
    "SalesToAwCollectn_Sathrs=Nakuru_Data.apply(lambda row: SatHrs(row[\"SalesOrderCreated\"], row['Awaitting_For_Collection']), axis=1)\n",
    "SalesToCollectn_Sathrs=Nakuru_Data.apply(lambda row: SatHrs(row[\"SalesOrderCreated\"], row['Collected']), axis=1)\n",
    "SateliteSending_Sathrs=Nakuru_Data.apply(lambda row: SatHrs(row[\"Satelite_Sending\"], row['Main_Receiving']), axis=1)\n",
    "SateliteReceiving_Sathrs=Nakuru_Data.apply(lambda row: SatHrs(row[\"Main_Sending\"], row['Awaitting_For_Collection']), axis=1)\n",
    "#######################################################\n",
    "Nakuru_Data[\"Duration\"]=(SalesToAwCollectn_Wkhrs+SalesToAwCollectn_Sathrs)*60 \n",
    "Nakuru_Data[\"Sales_To_Collected\"]=(SalesToCollectn_Wkhrs+SalesToCollectn_Sathrs)*60 \n",
    "Nakuru_Data[\"SateliteSendingTime\"]=(SateliteSending_Wkhrs+SateliteSending_Sathrs)*60 \n",
    "Nakuru_Data[\"SateliteReceivingTime\"]=(SateliteReceiving_Wkhrs+SateliteReceiving_Sathrs)*60 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3532e9c",
   "metadata": {},
   "source": [
    "### Eldoret and its Satelite Branches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc13fad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/2633932179.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Eldoret_Data[\"Duration\"]=(SalesToAwCollectn_Wkhrs+SalesToAwCollectn_Sathrs)*60\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/2633932179.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Eldoret_Data[\"Sales_To_Collected\"]=(SalesToCollectn_Wkhrs+SalesToCollectn_Sathrs)*60\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/2633932179.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Eldoret_Data[\"SateliteSendingTime\"]=(SateliteSending_Wkhrs+SateliteSending_Sathrs)*60\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/2633932179.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Eldoret_Data[\"SateliteReceivingTime\"]=(SateliteReceiving_Wkhrs+SateliteReceiving_Sathrs)*60\n"
     ]
    }
   ],
   "source": [
    "Eldoret_Branches=[\"ELD\",\"RUP\",\"HIG\"]\n",
    "Eldoret_Data=GlazingBranchesData[GlazingBranchesData[\"OrderProcess Branch\"].isin(Eldoret_Branches)]\n",
    "\n",
    "####Days of the week\n",
    "workday = businesstimedelta.WorkDayRule(start_time=datetime.time(9),end_time=datetime.time(18),working_days=[0,1, 2, 3, 4])\n",
    "vic_holidays = pyholidays.KE()\n",
    "holidays = businesstimedelta.HolidayRule(vic_holidays)\n",
    "from workalendar.africa import Kenya\n",
    "cal = Kenya()\n",
    "hl = cal.holidays()\n",
    "my_dict=dict(hl)\n",
    "vic_holidays=vic_holidays.append(my_dict)\n",
    "businesshrs = businesstimedelta.Rules([workday, holidays])\n",
    "\n",
    "def BusHrs(start, end):\n",
    "    if end>=start:\n",
    "        return businesshrs.difference(start,end).hours+float(businesshrs.difference(start,end).seconds)/float(3600)\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "SalesToAwCollectn_Wkhrs=Eldoret_Data.apply(lambda row: BusHrs(row[\"SalesOrderCreated\"], row['Awaitting_For_Collection']), axis=1)\n",
    "SalesToCollectn_Wkhrs=Eldoret_Data.apply(lambda row: BusHrs(row[\"SalesOrderCreated\"], row['Collected']), axis=1)\n",
    "SateliteSending_Wkhrs=Eldoret_Data.apply(lambda row: BusHrs(row[\"Satelite_Sending\"], row['Main_Receiving']), axis=1)\n",
    "SateliteReceiving_Wkhrs=Eldoret_Data.apply(lambda row: BusHrs(row[\"Main_Sending\"], row['Awaitting_For_Collection']), axis=1)\n",
    "####Weekends\n",
    "# Define a working weekend day(Saturday)\n",
    "\n",
    "Saturday = businesstimedelta.WorkDayRule(start_time=datetime.time(9),end_time=datetime.time(16),working_days=[5])\n",
    "\n",
    "businesshrs = businesstimedelta.Rules([Saturday, holidays])\n",
    "\n",
    "def SatHrs(start, end):\n",
    "    if end>=start:\n",
    "         return businesshrs.difference(start,end).hours+float(businesshrs.difference(start,end).seconds)/float(3600)\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "    \n",
    "SalesToAwCollectn_Sathrs=Eldoret_Data.apply(lambda row: SatHrs(row[\"SalesOrderCreated\"], row['Awaitting_For_Collection']), axis=1)\n",
    "SalesToCollectn_Sathrs=Eldoret_Data.apply(lambda row: SatHrs(row[\"SalesOrderCreated\"], row['Collected']), axis=1)\n",
    "SateliteSending_Sathrs=Eldoret_Data.apply(lambda row: SatHrs(row[\"Satelite_Sending\"], row['Main_Receiving']), axis=1)\n",
    "SateliteReceiving_Sathrs=Eldoret_Data.apply(lambda row: SatHrs(row[\"Main_Sending\"], row['Awaitting_For_Collection']), axis=1)\n",
    "#######################################################\n",
    "Eldoret_Data[\"Duration\"]=(SalesToAwCollectn_Wkhrs+SalesToAwCollectn_Sathrs)*60\n",
    "Eldoret_Data[\"Sales_To_Collected\"]=(SalesToCollectn_Wkhrs+SalesToCollectn_Sathrs)*60 \n",
    "Eldoret_Data[\"SateliteSendingTime\"]=(SateliteSending_Wkhrs+SateliteSending_Sathrs)*60 \n",
    "Eldoret_Data[\"SateliteReceivingTime\"]=(SateliteReceiving_Wkhrs+SateliteReceiving_Sathrs)*60 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98db4088",
   "metadata": {},
   "source": [
    "### Thika and its Satelite Branches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19f11888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3080755141.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Thika_Data[\"Duration\"]=(SalesToAwCollectn_Wkhrs+SalesToAwCollectn_Sathrs)*60\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3080755141.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Thika_Data[\"Sales_To_Collected\"]=(SalesToCollectn_Wkhrs+SalesToCollectn_Sathrs)*60\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3080755141.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Thika_Data[\"SateliteSendingTime\"]=(SateliteSending_Wkhrs+SateliteSending_Sathrs)*60\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3080755141.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Thika_Data[\"SateliteReceivingTime\"]=(SateliteReceiving_Wkhrs+SateliteReceiving_Sathrs)*60\n"
     ]
    }
   ],
   "source": [
    "Thika_Branches=[\"THI\",\"TBZ\"]\n",
    "Thika_Data=GlazingBranchesData[GlazingBranchesData[\"OrderProcess Branch\"].isin(Thika_Branches)]\n",
    "\n",
    "####Days of the week\n",
    "workday = businesstimedelta.WorkDayRule(start_time=datetime.time(8,30),end_time=datetime.time(17,30),working_days=[0,1, 2, 3, 4])\n",
    "vic_holidays = pyholidays.KE()\n",
    "holidays = businesstimedelta.HolidayRule(vic_holidays)\n",
    "from workalendar.africa import Kenya\n",
    "cal = Kenya()\n",
    "hl = cal.holidays()\n",
    "my_dict=dict(hl)\n",
    "vic_holidays=vic_holidays.append(my_dict)\n",
    "businesshrs = businesstimedelta.Rules([workday, holidays])\n",
    "\n",
    "def BusHrs(start, end):\n",
    "    if end>=start:\n",
    "        return businesshrs.difference(start,end).hours+float(businesshrs.difference(start,end).seconds)/float(3600)\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "SalesToAwCollectn_Wkhrs=Thika_Data.apply(lambda row: BusHrs(row[\"SalesOrderCreated\"], row['Awaitting_For_Collection']), axis=1)\n",
    "SalesToCollectn_Wkhrs=Thika_Data.apply(lambda row: BusHrs(row[\"SalesOrderCreated\"], row['Collected']), axis=1)\n",
    "SateliteSending_Wkhrs=Thika_Data.apply(lambda row: BusHrs(row[\"Satelite_Sending\"], row['Main_Receiving']), axis=1)\n",
    "SateliteReceiving_Wkhrs=Thika_Data.apply(lambda row: BusHrs(row[\"Main_Sending\"], row['Awaitting_For_Collection']), axis=1)\n",
    "####Weekends\n",
    "# Define a working weekend day(Saturday)\n",
    "\n",
    "Saturday = businesstimedelta.WorkDayRule(start_time=datetime.time(9),end_time=datetime.time(15),working_days=[5])\n",
    "\n",
    "businesshrs = businesstimedelta.Rules([Saturday, holidays])\n",
    "\n",
    "def SatHrs(start, end):\n",
    "    if end>=start:\n",
    "         return businesshrs.difference(start,end).hours+float(businesshrs.difference(start,end).seconds)/float(3600)\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "    \n",
    "SalesToAwCollectn_Sathrs=Thika_Data.apply(lambda row: SatHrs(row[\"SalesOrderCreated\"], row['Awaitting_For_Collection']), axis=1)\n",
    "SalesToCollectn_Sathrs=Thika_Data.apply(lambda row: SatHrs(row[\"SalesOrderCreated\"], row['Collected']), axis=1)\n",
    "SateliteSending_Sathrs=Thika_Data.apply(lambda row: SatHrs(row[\"Satelite_Sending\"], row['Main_Receiving']), axis=1)\n",
    "SateliteReceiving_Sathrs=Thika_Data.apply(lambda row: SatHrs(row[\"Main_Sending\"], row['Awaitting_For_Collection']), axis=1)\n",
    "#######################################################\n",
    "Thika_Data[\"Duration\"]=(SalesToAwCollectn_Wkhrs+SalesToAwCollectn_Sathrs)*60  \n",
    "Thika_Data[\"Sales_To_Collected\"]=(SalesToCollectn_Wkhrs+SalesToCollectn_Sathrs)*60 \n",
    "Thika_Data[\"SateliteSendingTime\"]=(SateliteSending_Wkhrs+SateliteSending_Sathrs)*60 \n",
    "Thika_Data[\"SateliteReceivingTime\"]=(SateliteReceiving_Wkhrs+SateliteReceiving_Sathrs)*60 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00847cfb",
   "metadata": {},
   "source": [
    "### Kisumu and its Satelite Branches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7181c2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3318987173.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Kisumu_Data[\"Duration\"]=(SalesToAwCollectn_Wkhrs+SalesToAwCollectn_Sathrs)*60\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3318987173.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Kisumu_Data[\"Sales_To_Collected\"]=(SalesToCollectn_Wkhrs+SalesToCollectn_Sathrs)*60\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3318987173.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Kisumu_Data[\"SateliteSendingTime\"]=(SateliteSending_Wkhrs+SateliteSending_Sathrs)*60\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3318987173.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Kisumu_Data[\"SateliteReceivingTime\"]=(SateliteReceiving_Wkhrs+SateliteReceiving_Sathrs)*60\n"
     ]
    }
   ],
   "source": [
    "Kisumu_Branches=[\"KIS\",\"KWE\",\"TUF\",\"UNI\"]\n",
    "Kisumu_Data=GlazingBranchesData[GlazingBranchesData[\"OrderProcess Branch\"].isin(Kisumu_Branches)]\n",
    "\n",
    "####Days of the week\n",
    "workday = businesstimedelta.WorkDayRule(start_time=datetime.time(9),end_time=datetime.time(18),working_days=[0,1, 2, 3, 4])\n",
    "vic_holidays = pyholidays.KE()\n",
    "holidays = businesstimedelta.HolidayRule(vic_holidays)\n",
    "from workalendar.africa import Kenya\n",
    "cal = Kenya()\n",
    "hl = cal.holidays()\n",
    "my_dict=dict(hl)\n",
    "vic_holidays=vic_holidays.append(my_dict)\n",
    "businesshrs = businesstimedelta.Rules([workday, holidays])\n",
    "\n",
    "def BusHrs(start, end):\n",
    "    if end>=start:\n",
    "        return businesshrs.difference(start,end).hours+float(businesshrs.difference(start,end).seconds)/float(3600)\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "SalesToAwCollectn_Wkhrs=Kisumu_Data.apply(lambda row: BusHrs(row[\"SalesOrderCreated\"], row['Awaitting_For_Collection']), axis=1)\n",
    "SalesToCollectn_Wkhrs=Kisumu_Data.apply(lambda row: BusHrs(row[\"SalesOrderCreated\"], row['Collected']), axis=1)\n",
    "SateliteSending_Wkhrs=Kisumu_Data.apply(lambda row: BusHrs(row[\"Satelite_Sending\"], row['Main_Receiving']), axis=1)\n",
    "SateliteReceiving_Wkhrs=Kisumu_Data.apply(lambda row: BusHrs(row[\"Main_Sending\"], row['Awaitting_For_Collection']), axis=1)\n",
    "####Weekends\n",
    "# Define a working weekend day(Saturday)\n",
    "\n",
    "Saturday = businesstimedelta.WorkDayRule(start_time=datetime.time(9),end_time=datetime.time(16),working_days=[5])\n",
    "\n",
    "businesshrs = businesstimedelta.Rules([Saturday, holidays])\n",
    "\n",
    "def SatHrs(start, end):\n",
    "    if end>=start:\n",
    "         return businesshrs.difference(start,end).hours+float(businesshrs.difference(start,end).seconds)/float(3600)\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "    \n",
    "SalesToAwCollectn_Sathrs=Kisumu_Data.apply(lambda row: SatHrs(row[\"SalesOrderCreated\"], row['Awaitting_For_Collection']), axis=1)\n",
    "SalesToCollectn_Sathrs=Kisumu_Data.apply(lambda row: SatHrs(row[\"SalesOrderCreated\"], row['Collected']), axis=1)\n",
    "SateliteSending_Sathrs=Kisumu_Data.apply(lambda row: SatHrs(row[\"Satelite_Sending\"], row['Main_Receiving']), axis=1)\n",
    "SateliteReceiving_Sathrs=Kisumu_Data.apply(lambda row: SatHrs(row[\"Main_Sending\"], row['Awaitting_For_Collection']), axis=1)\n",
    "#######################################################\n",
    "Kisumu_Data[\"Duration\"]=(SalesToAwCollectn_Wkhrs+SalesToAwCollectn_Sathrs)*60 \n",
    "Kisumu_Data[\"Sales_To_Collected\"]=(SalesToCollectn_Wkhrs+SalesToCollectn_Sathrs)*60 \n",
    "Kisumu_Data[\"SateliteSendingTime\"]=(SateliteSending_Wkhrs+SateliteSending_Sathrs)*60 \n",
    "Kisumu_Data[\"SateliteReceivingTime\"]=(SateliteReceiving_Wkhrs+SateliteReceiving_Sathrs)*60 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aa4dda",
   "metadata": {},
   "source": [
    "### Mombasa and its Satelite Branches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f957c0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/2234125780.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Mombasa_Data[\"Duration\"]=(SalesToAwCollectn_Wkhrs+SalesToAwCollectn_Sathrs)*60\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/2234125780.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Mombasa_Data[\"Sales_To_Collected\"]=(SalesToCollectn_Wkhrs+SalesToCollectn_Sathrs)*60\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/2234125780.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Mombasa_Data[\"SateliteSendingTime\"]=(SateliteSending_Wkhrs+SateliteSending_Sathrs)*60\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/2234125780.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Mombasa_Data[\"SateliteReceivingTime\"]=(SateliteReceiving_Wkhrs+SateliteReceiving_Sathrs)*60\n"
     ]
    }
   ],
   "source": [
    "Mombasa_Branches=[\"MSA\",\"NYA\",\"LIK\"]\n",
    "Mombasa_Data=GlazingBranchesData[GlazingBranchesData[\"OrderProcess Branch\"].isin(Mombasa_Branches)]\n",
    "\n",
    "####Days of the week\n",
    "workday = businesstimedelta.WorkDayRule(start_time=datetime.time(9),end_time=datetime.time(18),working_days=[0,1, 2, 3, 4])\n",
    "vic_holidays = pyholidays.KE()\n",
    "holidays = businesstimedelta.HolidayRule(vic_holidays)\n",
    "from workalendar.africa import Kenya\n",
    "cal = Kenya()\n",
    "hl = cal.holidays()\n",
    "my_dict=dict(hl)\n",
    "vic_holidays=vic_holidays.append(my_dict)\n",
    "businesshrs = businesstimedelta.Rules([workday, holidays])\n",
    "\n",
    "def BusHrs(start, end):\n",
    "    if end>=start:\n",
    "        return businesshrs.difference(start,end).hours+float(businesshrs.difference(start,end).seconds)/float(3600)\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "SalesToAwCollectn_Wkhrs=Mombasa_Data.apply(lambda row: BusHrs(row[\"SalesOrderCreated\"], row['Awaitting_For_Collection']), axis=1)\n",
    "SalesToCollectn_Wkhrs=Mombasa_Data.apply(lambda row: BusHrs(row[\"SalesOrderCreated\"], row['Collected']), axis=1)\n",
    "SateliteSending_Wkhrs=Mombasa_Data.apply(lambda row: BusHrs(row[\"Satelite_Sending\"], row['Main_Receiving']), axis=1)\n",
    "SateliteReceiving_Wkhrs=Mombasa_Data.apply(lambda row: BusHrs(row[\"Main_Sending\"], row['Awaitting_For_Collection']), axis=1)\n",
    "####Weekends\n",
    "# Define a working weekend day(Saturday)\n",
    "\n",
    "Saturday = businesstimedelta.WorkDayRule(start_time=datetime.time(9),end_time=datetime.time(16),working_days=[5])\n",
    "\n",
    "businesshrs = businesstimedelta.Rules([Saturday, holidays])\n",
    "\n",
    "def SatHrs(start, end):\n",
    "    if end>=start:\n",
    "         return businesshrs.difference(start,end).hours+float(businesshrs.difference(start,end).seconds)/float(3600)\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "    \n",
    "SalesToAwCollectn_Sathrs=Mombasa_Data.apply(lambda row: SatHrs(row[\"SalesOrderCreated\"], row['Awaitting_For_Collection']), axis=1)\n",
    "SalesToCollectn_Sathrs=Mombasa_Data.apply(lambda row: SatHrs(row[\"SalesOrderCreated\"], row['Collected']), axis=1)\n",
    "SateliteSending_Sathrs=Mombasa_Data.apply(lambda row: SatHrs(row[\"Satelite_Sending\"], row['Main_Receiving']), axis=1)\n",
    "SateliteReceiving_Sathrs=Mombasa_Data.apply(lambda row: SatHrs(row[\"Main_Sending\"], row['Awaitting_For_Collection']), axis=1)\n",
    "\n",
    "#######################################################\n",
    "Mombasa_Data[\"Duration\"]=(SalesToAwCollectn_Wkhrs+SalesToAwCollectn_Sathrs)*60 \n",
    "Mombasa_Data[\"Sales_To_Collected\"]=(SalesToCollectn_Wkhrs+SalesToCollectn_Sathrs)*60 \n",
    "Mombasa_Data[\"SateliteSendingTime\"]=(SateliteSending_Wkhrs+SateliteSending_Sathrs)*60 \n",
    "Mombasa_Data[\"SateliteReceivingTime\"]=(SateliteReceiving_Wkhrs+SateliteReceiving_Sathrs)*60 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02817744",
   "metadata": {},
   "source": [
    "### TRM and its Satelite Branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "962a231c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3855198092.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  TRM_Data[\"Duration\"]=(SalesToAwCollectn_Wkhrs+SalesToAwCollectn_Sathrs+SalesToAwCollectn_Sunhrs)*60\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3855198092.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  TRM_Data[\"Sales_To_Collected\"]=(SalesToCollectn_Wkhrs+SalesToCollectn_Sathrs+SalesToCollectn_Sunhrs)*60\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3855198092.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  TRM_Data[\"SateliteSendingTime\"]=(SateliteSending_Wkhrs+SateliteSending_Sathrs+SateliteSending_Sunhrs)*60\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3855198092.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  TRM_Data[\"SateliteReceivingTime\"]=(SateliteReceiving_Wkhrs+SateliteReceiving_Sathrs+SateliteReceiving_Sunhrs)*60\n"
     ]
    }
   ],
   "source": [
    "TRM_Branches=[\"TRM\",\"GAR\"]\n",
    "TRM_Data=GlazingBranchesData[GlazingBranchesData[\"OrderProcess Branch\"].isin(TRM_Branches)]\n",
    "\n",
    "####Days of the week\n",
    "workday = businesstimedelta.WorkDayRule(start_time=datetime.time(10),end_time=datetime.time(19),working_days=[0,1, 2, 3, 4])\n",
    "vic_holidays = pyholidays.KE()\n",
    "holidays = businesstimedelta.HolidayRule(vic_holidays)\n",
    "from workalendar.africa import Kenya\n",
    "cal = Kenya()\n",
    "hl = cal.holidays()\n",
    "my_dict=dict(hl)\n",
    "vic_holidays=vic_holidays.append(my_dict)\n",
    "businesshrs = businesstimedelta.Rules([workday, holidays])\n",
    "\n",
    "def BusHrs(start, end):\n",
    "    if end>=start:\n",
    "        return businesshrs.difference(start,end).hours+float(businesshrs.difference(start,end).seconds)/float(3600)\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "SalesToAwCollectn_Wkhrs=TRM_Data.apply(lambda row: BusHrs(row[\"SalesOrderCreated\"], row['Awaitting_For_Collection']), axis=1)\n",
    "SalesToCollectn_Wkhrs=TRM_Data.apply(lambda row: BusHrs(row[\"SalesOrderCreated\"], row['Collected']), axis=1)\n",
    "SateliteSending_Wkhrs=TRM_Data.apply(lambda row: BusHrs(row[\"Satelite_Sending\"], row['Main_Receiving']), axis=1)\n",
    "SateliteReceiving_Wkhrs=TRM_Data.apply(lambda row: BusHrs(row[\"Main_Sending\"], row['Awaitting_For_Collection']), axis=1)\n",
    "####Weekends\n",
    "# Define a working weekend day(Saturday)\n",
    "\n",
    "Saturday = businesstimedelta.WorkDayRule(start_time=datetime.time(10),end_time=datetime.time(18,30),working_days=[5])\n",
    "\n",
    "businesshrs = businesstimedelta.Rules([Saturday, holidays])\n",
    "\n",
    "def SatHrs(start, end):\n",
    "    if end>=start:\n",
    "         return businesshrs.difference(start,end).hours+float(businesshrs.difference(start,end).seconds)/float(3600)\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "    \n",
    "SalesToAwCollectn_Sathrs=TRM_Data.apply(lambda row: SatHrs(row[\"SalesOrderCreated\"], row['Awaitting_For_Collection']), axis=1)\n",
    "SalesToCollectn_Sathrs=TRM_Data.apply(lambda row: SatHrs(row[\"SalesOrderCreated\"], row['Collected']), axis=1)\n",
    "SateliteSending_Sathrs=TRM_Data.apply(lambda row: SatHrs(row[\"Satelite_Sending\"], row['Main_Receiving']), axis=1)\n",
    "SateliteReceiving_Sathrs=TRM_Data.apply(lambda row: SatHrs(row[\"Main_Sending\"], row['Awaitting_For_Collection']), axis=1)\n",
    "\n",
    "\n",
    "# Define a working weekend day(Sunday)\n",
    "\n",
    "Sunday = businesstimedelta.WorkDayRule(start_time=datetime.time(11),end_time=datetime.time(17),working_days=[6])\n",
    "\n",
    "businesshrs = businesstimedelta.Rules([Sunday, holidays])\n",
    "\n",
    "def SunHrs(start, end):\n",
    "    if end>=start:\n",
    "         return businesshrs.difference(start,end).hours+float(businesshrs.difference(start,end).seconds)/float(3600)\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "    \n",
    "SalesToAwCollectn_Sunhrs=TRM_Data.apply(lambda row: SunHrs(row[\"SalesOrderCreated\"], row['Awaitting_For_Collection']), axis=1)\n",
    "SalesToCollectn_Sunhrs=TRM_Data.apply(lambda row: SunHrs(row[\"SalesOrderCreated\"], row['Collected']), axis=1)\n",
    "SateliteSending_Sunhrs=TRM_Data.apply(lambda row: SatHrs(row[\"Satelite_Sending\"], row['Main_Receiving']), axis=1)\n",
    "SateliteReceiving_Sunhrs=TRM_Data.apply(lambda row: SatHrs(row[\"Main_Sending\"], row['Awaitting_For_Collection']), axis=1)\n",
    "#######################################################\n",
    "TRM_Data[\"Duration\"]=(SalesToAwCollectn_Wkhrs+SalesToAwCollectn_Sathrs+SalesToAwCollectn_Sunhrs)*60\n",
    "TRM_Data[\"Sales_To_Collected\"]=(SalesToCollectn_Wkhrs+SalesToCollectn_Sathrs+SalesToCollectn_Sunhrs)*60 \n",
    "TRM_Data[\"SateliteSendingTime\"]=(SateliteSending_Wkhrs+SateliteSending_Sathrs+SateliteSending_Sunhrs)*60 \n",
    "TRM_Data[\"SateliteReceivingTime\"]=(SateliteReceiving_Wkhrs+SateliteReceiving_Sathrs+SateliteReceiving_Sunhrs)*60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b46f31e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_GlazingBranchesData=pd.concat([Nakuru_Data,Eldoret_Data,Thika_Data,Mombasa_Data,Kisumu_Data,TRM_Data])\n",
    "GlazingBranchesData[~GlazingBranchesData[\"DocEntry\"].isin(Final_GlazingBranchesData[\"DocEntry\"])]\n",
    "Final_GlazingBranchesData[\"Duration\"]=pd.to_numeric(Final_GlazingBranchesData[\"Duration\"])\n",
    "Final_GlazingBranchesData[\"Sales_To_Collected\"]=pd.to_numeric(Final_GlazingBranchesData[\"Sales_To_Collected\"])\n",
    "Final_GlazingBranchesData[\"SateliteSendingTime\"]=pd.to_numeric(Final_GlazingBranchesData[\"SateliteSendingTime\"])\n",
    "Final_GlazingBranchesData[\"SateliteReceivingTime\"]=pd.to_numeric(Final_GlazingBranchesData[\"SateliteReceivingTime\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe91ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40e89272",
   "metadata": {},
   "source": [
    "### Grouping the Duration Taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fac1b4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3122629012.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Main_GlazingBranchesData[\"Category\"]=np.where(Main_GlazingBranchesData.Duration<=15,\"Ready Within 15 Min\",\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3122629012.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Satelite_GlazingBranchesData[\"Category\"]=np.where(Satelite_GlazingBranchesData.Duration<=60,\"Ready Within 1hr\",\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3122629012.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Main_GlazingBranchesData[\"Category(collected)\"]=np.where(Main_GlazingBranchesData.Sales_To_Collected.isnull(),\"Not Yet Collected\",\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3122629012.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Satelite_GlazingBranchesData[\"Category(collected)\"]=np.where(Satelite_GlazingBranchesData.Sales_To_Collected.isnull(),\"Not Yet Collected\",\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Main_GlazingBranchesData=Final_GlazingBranchesData[Final_GlazingBranchesData[\"Outlet\"].isin([\"KIS\",\"ELD\",\"NAK\",\"THI\",\"TRM\",\"MSA\"])]\n",
    "Satelite_GlazingBranchesData=Final_GlazingBranchesData[~Final_GlazingBranchesData[\"Outlet\"].isin([\"KIS\",\"ELD\",\"NAK\",\"THI\",\"TRM\",\"MSA\"])]\n",
    "\n",
    "###Sales Created to Awaiting for Collection\n",
    "Main_GlazingBranchesData[\"Category\"]=np.where(Main_GlazingBranchesData.Duration<=15,\"Ready Within 15 Min\",\n",
    "                                              np.where(Main_GlazingBranchesData.Duration<=30,\"Ready btwn 16 - 30 Min\",\n",
    "                                                      \"Greater than 30mins\"))\n",
    "                                                   \n",
    "Satelite_GlazingBranchesData[\"Category\"]=np.where(Satelite_GlazingBranchesData.Duration<=60,\"Ready Within 1hr\",\n",
    "                                              np.where(Satelite_GlazingBranchesData.Duration<=120,\"Ready btwn >1 -2hrs\",\n",
    "                                                       np.where(Satelite_GlazingBranchesData.Duration<=180,\"Ready btwn >2 -3hrs\",\n",
    "                                                                np.where(Satelite_GlazingBranchesData.Duration<=240,\"Ready btwn >3 -4hrs\",\n",
    "                                                    \n",
    "                                                      \"Greater than 4hrs\"))))\n",
    "\n",
    "###Sales Created to  Collection\n",
    "\n",
    "Main_GlazingBranchesData[\"Category(collected)\"]=np.where(Main_GlazingBranchesData.Sales_To_Collected.isnull(),\"Not Yet Collected\",\n",
    "                                                         np.where(Main_GlazingBranchesData.Sales_To_Collected<=15,\"Ready Within 15 Min\",\n",
    "                                              np.where(Main_GlazingBranchesData.Sales_To_Collected<=30,\"Ready btwn 16 - 30 Min\",\n",
    "                                                      \"Greater than 30mins\")))\n",
    "                                                   \n",
    "Satelite_GlazingBranchesData[\"Category(collected)\"]=np.where(Satelite_GlazingBranchesData.Sales_To_Collected.isnull(),\"Not Yet Collected\",\n",
    "                                                             np.where(Satelite_GlazingBranchesData.Sales_To_Collected<=60,\"Ready Within 1hr\",\n",
    "                                              np.where(Satelite_GlazingBranchesData.Sales_To_Collected<=120,\"Ready btwn >1 -2hrs\",\n",
    "                                                       np.where(Satelite_GlazingBranchesData.Sales_To_Collected<=180,\"Ready btwn >2 -3hrs\",\n",
    "                                                                np.where(Satelite_GlazingBranchesData.Sales_To_Collected<=240,\"Ready btwn >3 -4hrs\",\n",
    "                                                                         \"Greater than 4hrs\")))))\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "###Satelite Branches Sending the Orders\n",
    "data=Final_GlazingBranchesData\n",
    "data[\"Category(Sending)\"]=np.where(data.SateliteSendingTime.isnull(),\"Not Yet\",\n",
    "                                                       np.where(data.SateliteSendingTime<=30,\"Arrived within 30 Min\",\n",
    "                                                                np.where(data.SateliteSendingTime<=60,\"Arrived >30 to 60 Min\",\n",
    "                                                                         np.where(data.SateliteSendingTime<=120,\"Arrived >1hr to 2hr\",\n",
    "                                                                                  \"Arrived in >2hr\"))))\n",
    "\n",
    "###Satelite Branches Receiving the Orders\n",
    "\n",
    "data[\"Category(Receiving)\"]=np.where(data.SateliteReceivingTime.isnull(),\"Not Yet\",\n",
    "                                                         np.where(data.SateliteReceivingTime<=30,\"Received within 30 Min\",\n",
    "                                                                  np.where(data.SateliteReceivingTime<=60,\"Received >30 to 60 Min\",\n",
    "                                                                           np.where(data.SateliteReceivingTime<=120,\"Received >1hr to 2hr\",\n",
    "                                                                                    \"Received in >2hr\"))))\n",
    "                                                       \n",
    "                                                   \n",
    "\n",
    "\n",
    "                                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a670ac",
   "metadata": {},
   "source": [
    "### Aggregations via Pivot tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36a6f94",
   "metadata": {},
   "source": [
    "### A. Sales Order Created to  Awaiting for Collection and to Finaly Collected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ac3dda",
   "metadata": {},
   "source": [
    "#### 1. Main Branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cccf69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/1641852220.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Main_Branches_Pivot_mean[\"Metric\"]=\"Average Time (mins)\"\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/1641852220.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Main_Branches_Pivot_Counts[\"Metric\"]=\"Order Count\"\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/1641852220.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Main_Branches_Pivot2_mean[\"Metric\"]=\"Average Time (mins)\"\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/1641852220.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Main_Branches_Pivot2_Counts[\"Metric\"]=\"Order Count\"\n"
     ]
    }
   ],
   "source": [
    "###Sales Created to Awaiting for Collection\n",
    "Main_Branches_Pivot=pd.pivot_table(Main_GlazingBranchesData,index=\"Outlet\",columns=\"Category\",values=\"Duration\",\n",
    "                                   aggfunc=[\"count\",\"mean\"],margins=True)\n",
    "\n",
    "Main_Branches_Pivot_Counts=Main_Branches_Pivot[[\"count\"]]\n",
    "Main_Branches_Pivot_Counts.columns = Main_Branches_Pivot_Counts.columns.droplevel(0)\n",
    "Main_Branches_Pivot_mean=Main_Branches_Pivot[[\"mean\"]]\n",
    "Main_Branches_Pivot_mean.columns = Main_Branches_Pivot_mean.columns.droplevel(0)\n",
    "Main_Branches_Pivot_mean[\"Metric\"]=\"Average Time (mins)\"\n",
    "Main_Branches_Pivot_Counts[\"Metric\"]=\"Order Count\"\n",
    "Main_Branches_Pivot_mean=Main_Branches_Pivot_mean[[\"Metric\",\"Ready Within 15 Min\",\"Ready btwn 16 - 30 Min\",\"Greater than 30mins\",\n",
    "                                                  \"All\"]]\n",
    "\n",
    "Main_Branches_Pivot_Counts=Main_Branches_Pivot_Counts[[\"Metric\",\"Ready Within 15 Min\",\"Ready btwn 16 - 30 Min\",\"Greater than 30mins\",\n",
    "                                                  \"All\"]]\n",
    "\n",
    "Main_Branches_Pivot_Counts[\"%_ge Ready Within 30mins\"]=(((Main_Branches_Pivot_Counts[\"Ready Within 15 Min\"])+(Main_Branches_Pivot_Counts[\"Ready btwn 16 - 30 Min\"]))/Main_Branches_Pivot_Counts[\"All\"])*100\n",
    "\n",
    "Final_Main_Branches_Pivot=pd.concat([Main_Branches_Pivot_mean,Main_Branches_Pivot_Counts])\n",
    "Final_Main_Branches_Pivot=Final_Main_Branches_Pivot.reset_index()\n",
    "\n",
    "###Sales Created to  Collection\n",
    "\n",
    "Main_Branches_Pivot2=pd.pivot_table(Main_GlazingBranchesData,index=\"Outlet\",columns=\"Category(collected)\",values=\"Sales_To_Collected\",\n",
    "                                   aggfunc=[\"count\",\"mean\"],margins=True)\n",
    "\n",
    "Main_Branches_Pivot2_Counts=Main_Branches_Pivot2[[\"count\"]]\n",
    "Main_Branches_Pivot2_Counts.columns = Main_Branches_Pivot2_Counts.columns.droplevel(0)\n",
    "Main_Branches_Pivot2_mean=Main_Branches_Pivot2[[\"mean\"]]\n",
    "Main_Branches_Pivot2_mean.columns = Main_Branches_Pivot2_mean.columns.droplevel(0)\n",
    "Main_Branches_Pivot2_mean[\"Metric\"]=\"Average Time (mins)\"\n",
    "Main_Branches_Pivot2_Counts[\"Metric\"]=\"Order Count\"\n",
    "Main_Branches_Pivot2_mean=Main_Branches_Pivot2_mean[[\"Metric\",\"Ready Within 15 Min\",\"Ready btwn 16 - 30 Min\",\"Greater than 30mins\",\n",
    "                                                  \"All\"]]\n",
    "\n",
    "Main_Branches_Pivot2_Counts=Main_Branches_Pivot2_Counts[[\"Metric\",\"Ready Within 15 Min\",\"Ready btwn 16 - 30 Min\",\"Greater than 30mins\",\n",
    "                                                  \"All\"]]\n",
    "\n",
    "Main_Branches_Pivot2_Counts[\"%_ge Ready Within 30mins\"]=(((Main_Branches_Pivot2_Counts[\"Ready Within 15 Min\"])+(Main_Branches_Pivot2_Counts[\"Ready btwn 16 - 30 Min\"]))/Main_Branches_Pivot2_Counts[\"All\"])*100\n",
    "\n",
    "Final_Main_Branches_Pivot2=pd.concat([Main_Branches_Pivot2_mean,Main_Branches_Pivot2_Counts])\n",
    "Final_Main_Branches_Pivot2=Final_Main_Branches_Pivot2.reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3820be1",
   "metadata": {},
   "source": [
    "#### 2. Satelite  Branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3d40c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/2279123528.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Satelite_Branches_Pivot_mean[\"Metric\"]=\"Average Time (mins)\"\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/2279123528.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Satelite_Branches_Pivot_Counts[\"Metric\"]=\"Order Count\"\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/2279123528.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Satelite_Branches_Pivot2_mean[\"Metric\"]=\"Average Time (mins)\"\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/2279123528.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Satelite_Branches_Pivot2_Counts[\"Metric\"]=\"Order Count\"\n"
     ]
    }
   ],
   "source": [
    "###Sales Created to Awaiting for Collection\n",
    "Satelite_Branches_Pivot=pd.pivot_table(Satelite_GlazingBranchesData,index=\"Outlet\",columns=\"Category\",values=\"Duration\",\n",
    "                                   aggfunc=[\"count\",\"mean\"],margins=True)\n",
    "\n",
    "Satelite_Branches_Pivot_Counts=Satelite_Branches_Pivot[[\"count\"]]\n",
    "Satelite_Branches_Pivot_Counts.columns = Satelite_Branches_Pivot_Counts.columns.droplevel(0)\n",
    "Satelite_Branches_Pivot_mean=Satelite_Branches_Pivot[[\"mean\"]]\n",
    "Satelite_Branches_Pivot_mean.columns = Satelite_Branches_Pivot_mean.columns.droplevel(0)\n",
    "Satelite_Branches_Pivot_mean[\"Metric\"]=\"Average Time (mins)\"\n",
    "Satelite_Branches_Pivot_Counts[\"Metric\"]=\"Order Count\"\n",
    "Satelite_Branches_Pivot_mean=Satelite_Branches_Pivot_mean[[\"Metric\",\"Ready Within 1hr\",\"Ready btwn >1 -2hrs\",\"Ready btwn >1 -2hrs\",\"Ready btwn >2 -3hrs\",\n",
    "                                                  \"Ready btwn >3 -4hrs\",\"Ready btwn >3 -4hrs\",\"Greater than 4hrs\",\"All\"]]\n",
    "\n",
    "Satelite_Branches_Pivot_Counts=Satelite_Branches_Pivot_Counts[[\"Metric\",\"Ready Within 1hr\",\"Ready btwn >1 -2hrs\",\"Ready btwn >1 -2hrs\",\"Ready btwn >2 -3hrs\",\n",
    "                                                  \"Ready btwn >3 -4hrs\",\"Ready btwn >3 -4hrs\",\"Greater than 4hrs\",\"All\"]]\n",
    "\n",
    "#Satelite_Branches_Pivot_Counts[\"%_ge Ready Within 1hr\"]=(Satelite_Branches_Pivot_Counts[\"Ready Within 1hr\"]/Satelite_Branches_Pivot_Counts[\"All\"])*100\n",
    "Final_Satelite_Branches_Pivot=pd.concat([Satelite_Branches_Pivot_mean,Satelite_Branches_Pivot_Counts])\n",
    "Final_Satelite_Branches_Pivot=Final_Satelite_Branches_Pivot.reset_index()\n",
    "Final_Satelite_Branches_Pivot\n",
    "\n",
    "###Sales Created to  Collection\n",
    "\n",
    "Satelite_Branches_Pivot2=pd.pivot_table(Satelite_GlazingBranchesData,index=\"Outlet\",columns=\"Category(collected)\",values=\"Sales_To_Collected\",\n",
    "                                   aggfunc=[\"count\",\"mean\"],margins=True)\n",
    "\n",
    "Satelite_Branches_Pivot2_Counts=Satelite_Branches_Pivot2[[\"count\"]]\n",
    "Satelite_Branches_Pivot2_Counts.columns = Satelite_Branches_Pivot2_Counts.columns.droplevel(0)\n",
    "Satelite_Branches_Pivot2_mean=Satelite_Branches_Pivot2[[\"mean\"]]\n",
    "Satelite_Branches_Pivot2_mean.columns = Satelite_Branches_Pivot2_mean.columns.droplevel(0)\n",
    "Satelite_Branches_Pivot2_mean[\"Metric\"]=\"Average Time (mins)\"\n",
    "Satelite_Branches_Pivot2_Counts[\"Metric\"]=\"Order Count\"\n",
    "Satelite_Branches_Pivot2_mean=Satelite_Branches_Pivot2_mean[[\"Metric\",\"Ready Within 1hr\",\"Ready btwn >1 -2hrs\",\"Ready btwn >1 -2hrs\",\"Ready btwn >2 -3hrs\",\n",
    "                                                  \"Ready btwn >3 -4hrs\",\"Ready btwn >3 -4hrs\",\"Greater than 4hrs\",\"All\"]]\n",
    "\n",
    "Satelite_Branches_Pivot2_Counts=Satelite_Branches_Pivot2_Counts[[\"Metric\",\"Ready Within 1hr\",\"Ready btwn >1 -2hrs\",\"Ready btwn >1 -2hrs\",\"Ready btwn >2 -3hrs\",\n",
    "                                                  \"Ready btwn >3 -4hrs\",\"Ready btwn >3 -4hrs\",\"Greater than 4hrs\",\"All\"]]\n",
    "\n",
    "#Satelite_Branches_Pivot_Counts[\"%_ge Ready Within 1hr\"]=(Satelite_Branches_Pivot_Counts[\"Ready Within 1hr\"]/Satelite_Branches_Pivot_Counts[\"All\"])*100\n",
    "Final_Satelite_Branches_Pivot2=pd.concat([Satelite_Branches_Pivot2_mean,Satelite_Branches_Pivot2_Counts])\n",
    "Final_Satelite_Branches_Pivot2=Final_Satelite_Branches_Pivot2.reset_index()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51e9166a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Arrived within 30 Min', 'Arrived >30 to 60 Min',\n",
       "       'Arrived >1hr to 2hr', 'Arrived in >2hr', 'Not Yet'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Category(Sending)\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109e6890",
   "metadata": {},
   "source": [
    "### B. Satelite Branches Sending Orders and Receiving Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2c0a318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3841032386.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Main_Branches_Pivot_mean[\"Metric\"]=\"Average Time (mins)\"\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3841032386.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Main_Branches_Pivot_Counts[\"Metric\"]=\"Order Count\"\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3841032386.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Main_Branches_Pivot_mean[\"Metric\"]=\"Average Time (mins)\"\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12032/3841032386.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Main_Branches_Pivot_Counts[\"Metric\"]=\"Order Count\"\n"
     ]
    }
   ],
   "source": [
    "###Satelite Branches Sending Orders\n",
    "Main_Branches_Pivot=pd.pivot_table(data,index=\"Outlet\",columns=\"Category(Sending)\",values=\"SateliteSendingTime\",\n",
    "                                   aggfunc=[\"count\",\"mean\"],margins=True)\n",
    "\n",
    "Main_Branches_Pivot_Counts=Main_Branches_Pivot[[\"count\"]]\n",
    "Main_Branches_Pivot_Counts.columns = Main_Branches_Pivot_Counts.columns.droplevel(0)\n",
    "Main_Branches_Pivot_mean=Main_Branches_Pivot[[\"mean\"]]\n",
    "Main_Branches_Pivot_mean.columns = Main_Branches_Pivot_mean.columns.droplevel(0)\n",
    "Main_Branches_Pivot_mean[\"Metric\"]=\"Average Time (mins)\"\n",
    "Main_Branches_Pivot_Counts[\"Metric\"]=\"Order Count\"\n",
    "# Main_Branches_Pivot_mean=Main_Branches_Pivot_mean[[\"Metric\",\"Arrived within 30 Min\",\"Arrived >30 to 60 Min\",\"Arrived >1hr to 2hr\",\n",
    "#                                                   \"Arrived in >2hr\",\"All\"]]\n",
    "\n",
    "# Main_Branches_Pivot_Counts=Main_Branches_Pivot_Counts[[\"Metric\",\"Arrived within 30 Min\",\"Arrived >30 to 60 Min\",\"Arrived >1hr to 2hr\",\n",
    "#                                                   \"Arrived in >2hr\",\"All\"]]\n",
    "\n",
    "Final_SateliteBranchesSending=pd.concat([Main_Branches_Pivot_mean,Main_Branches_Pivot_Counts])\n",
    "Final_SateliteBranchesSending=Final_SateliteBranchesSending.reset_index()\n",
    "\n",
    "###Satelite Branches Receiving Orders\n",
    "\n",
    "Main_Branches_Pivot=pd.pivot_table(data,index=\"Outlet\",columns=\"Category(Receiving)\",values=\"SateliteReceivingTime\",\n",
    "                                   aggfunc=[\"count\",\"mean\"],margins=True)\n",
    "\n",
    "Main_Branches_Pivot_Counts=Main_Branches_Pivot[[\"count\"]]\n",
    "Main_Branches_Pivot_Counts.columns = Main_Branches_Pivot_Counts.columns.droplevel(0)\n",
    "Main_Branches_Pivot_mean=Main_Branches_Pivot[[\"mean\"]]\n",
    "Main_Branches_Pivot_mean.columns = Main_Branches_Pivot_mean.columns.droplevel(0)\n",
    "Main_Branches_Pivot_mean[\"Metric\"]=\"Average Time (mins)\"\n",
    "Main_Branches_Pivot_Counts[\"Metric\"]=\"Order Count\"\n",
    "# Main_Branches_Pivot_mean=Main_Branches_Pivot_mean[[\"Metric\",\"Arrived within 30 Min\",\"Arrived >30 to 60 Min\",\"Arrived >1hr to 2hr\",\n",
    "#                                                   \"Arrived in >2hr\",\"All\"]]\n",
    "\n",
    "# Main_Branches_Pivot_Counts=Main_Branches_Pivot_Counts[[\"Metric\",\"Arrived within 30 Min\",\"Arrived >30 to 60 Min\",\"Arrived >1hr to 2hr\",\n",
    "#                                                   \"Arrived in >2hr\",\"All\"]]\n",
    "\n",
    "Final_SateliteBranchesReceiving=pd.concat([Main_Branches_Pivot_mean,Main_Branches_Pivot_Counts])\n",
    "Final_SateliteBranchesReceiving=Final_SateliteBranchesReceiving.reset_index()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9c22a5",
   "metadata": {},
   "source": [
    "### Writing to excel file time taken from Sales order created to Awaiting for Collection and final Collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08b7cc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xlsxwriter\\workbook.py:339: UserWarning: Calling close() on already closed file.\n",
      "  warn(\"Calling close() on already closed file.\")\n"
     ]
    }
   ],
   "source": [
    "#!pip install xlsxwriter --upgrade\n",
    "\n",
    "import xlsxwriter\n",
    "print(xlsxwriter.__version__)\n",
    "\n",
    "\n",
    "#Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "with pd.ExcelWriter(r\"C:\\Users\\HP\\Documents\\Master\\Reports\\Wairimu Mathenge\\Glazing Branches\\SalesOrderToAwaitingCollected_GlazingReport.xlsx\", engine='xlsxwriter') as writer:    \n",
    "        Final_Main_Branches_Pivot.to_excel(writer,sheet_name=\"MainBranches_AwatnCollection\", index=False)\n",
    "        Final_Satelite_Branches_Pivot.to_excel(writer,sheet_name=\"SateliteBranches_AwtnCollection\", index=False)\n",
    "        for group, dataframe in Final_Main_Branches_Pivot.groupby('Outlet'):\n",
    "            # save the dataframe for each group to a csv\n",
    "            dataframe = dataframe.drop([\"Outlet\"],axis=1)\n",
    "            name = f'{group}'\n",
    "            dataframe.to_excel(writer,sheet_name=name, index=False)\n",
    "        for group, dataframe in Final_Satelite_Branches_Pivot.groupby('Outlet'):\n",
    "            # save the dataframe for each group to a csv\n",
    "            dataframe = dataframe.drop([\"Outlet\"],axis=1)\n",
    "            name = f'{group}'\n",
    "            dataframe.to_excel(writer,sheet_name=name, index=False)\n",
    "        \n",
    "writer.save()\n",
    "\n",
    "def save_xls(list_dfs, xls_path):\n",
    "    with ExcelWriter(xls_path) as writer:\n",
    "        for n, df in enumerate(list_dfs):\n",
    "            df.to_excel(writer,'sheet%s' % n)\n",
    "        writer.save()\n",
    "######################################################################################################\n",
    "\n",
    "with pd.ExcelWriter(r\"C:\\Users\\HP\\Documents\\Master\\Reports\\Wairimu Mathenge\\Glazing Branches\\SalesOrderToCollected_GlazingReport.xlsx\", engine='xlsxwriter') as writer:    \n",
    "        Final_Main_Branches_Pivot2.to_excel(writer,sheet_name=\"MainBranches_Collection\", index=False)\n",
    "        Final_Satelite_Branches_Pivot2.to_excel(writer,sheet_name=\"SateliteBranches_Collection\", index=False)\n",
    "        for group, dataframe in Final_Main_Branches_Pivot2.groupby('Outlet'):\n",
    "            # save the dataframe for each group to a csv\n",
    "            dataframe = dataframe.drop([\"Outlet\"],axis=1)\n",
    "            name = f'{group}'\n",
    "            #dataframe=dataframe.transpose()\n",
    "            dataframe.to_excel(writer,sheet_name=name, index=False)\n",
    "        for group, dataframe in Final_Satelite_Branches_Pivot2.groupby('Outlet'):\n",
    "            # save the dataframe for each group to a csv\n",
    "            dataframe = dataframe.drop([\"Outlet\"],axis=1)\n",
    "            name = f'{group}'\n",
    "            #dataframe=dataframe.transpose()\n",
    "            dataframe.to_excel(writer,sheet_name=name, index=False)\n",
    "        \n",
    "writer.save()\n",
    "\n",
    "def save_xls(list_dfs, xls_path):\n",
    "    with ExcelWriter(xls_path) as writer:\n",
    "        for n, df in enumerate(list_dfs):\n",
    "            df.to_excel(writer,'sheet%s' % n)\n",
    "        writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475fa4d8",
   "metadata": {},
   "source": [
    "### Writing to excel file time taken for Satelite Branches to Sent and Receive Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38139274",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_SateliteBranchesSending=Final_SateliteBranchesSending[~Final_SateliteBranchesSending.Outlet.isin([\"KIS\",\"ELD\",\"NAK\",\"THI\",\"TRM\",\"MSA\"])]\n",
    "with pd.ExcelWriter(r\"C:\\Users\\HP\\Documents\\Master\\Reports\\Wairimu Mathenge\\Glazing Branches\\SateliteSending_GlazingReport.xlsx\", engine='xlsxwriter') as writer:    \n",
    "        for group, dataframe in Final_SateliteBranchesSending.groupby('Outlet'):\n",
    "            # save the dataframe for each group to a csv\n",
    "            dataframe = dataframe.drop([\"Outlet\"],axis=1)\n",
    "            name = f'{group}'\n",
    "            dataframe.to_excel(writer,sheet_name=name, index=False)\n",
    "            \n",
    "writer.save()\n",
    "\n",
    "def save_xls(list_dfs, xls_path):\n",
    "    with ExcelWriter(xls_path) as writer:\n",
    "        for n, df in enumerate(list_dfs):\n",
    "            df.to_excel(writer,'sheet%s' % n)\n",
    "        writer.save()\n",
    "        \n",
    "##########################################################################################\n",
    "Final_SateliteBranchesReceiving=Final_SateliteBranchesReceiving[~Final_SateliteBranchesReceiving.Outlet.isin([\"KIS\",\"ELD\",\"NAK\",\"THI\",\"TRM\",\"MSA\"])]\n",
    "with pd.ExcelWriter(r\"C:\\Users\\HP\\Documents\\Master\\Reports\\Wairimu Mathenge\\Glazing Branches\\SateliteReceiving_GlazingReport.xlsx\", engine='xlsxwriter') as writer:    \n",
    "        for group, dataframe in Final_SateliteBranchesReceiving.groupby('Outlet'):\n",
    "            # save the dataframe for each group to a csv\n",
    "            dataframe = dataframe.drop([\"Outlet\"],axis=1)\n",
    "            name = f'{group}'\n",
    "            dataframe.to_excel(writer,sheet_name=name, index=False)\n",
    "            \n",
    "writer.save()\n",
    "\n",
    "def save_xls(list_dfs, xls_path):\n",
    "    with ExcelWriter(xls_path) as writer:\n",
    "        for n, df in enumerate(list_dfs):\n",
    "            df.to_excel(writer,'sheet%s' % n)\n",
    "        writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880268e3",
   "metadata": {},
   "source": [
    "### Writting to excel Detailes Data and Also the into excel sheets per branch for the orders that took more than 30 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0181ff77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xlsxwriter\\workbook.py:339: UserWarning: Calling close() on already closed file.\n",
      "  warn(\"Calling close() on already closed file.\")\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xlsxwriter\\workbook.py:339: UserWarning: Calling close() on already closed file.\n",
      "  warn(\"Calling close() on already closed file.\")\n"
     ]
    }
   ],
   "source": [
    "#detailed_data=pd.concat([Main_GlazingBranchesData,Satelite_GlazingBranchesData])\n",
    "with pd.ExcelWriter(r\"C:\\Users\\HP\\Documents\\Master\\Reports\\Wairimu Mathenge\\Glazing Branches\\Details_GlazingReport.xlsx\", engine='xlsxwriter') as writer:    \n",
    "        Final_GlazingBranchesData.to_excel(writer,sheet_name=\"Details\", index=False)\n",
    "              \n",
    "writer.save()\n",
    "\n",
    "def save_xls(list_dfs, xls_path):\n",
    "    with ExcelWriter(xls_path) as writer:\n",
    "        for n, df in enumerate(list_dfs):\n",
    "            df.to_excel(writer,'sheet%s' % n)\n",
    "        writer.save()\n",
    "        \n",
    "######################################################################################################################\n",
    "Morethan30mins=Main_GlazingBranchesData[[\"Order No.\",\"OrderProcess Branch\",\"OrderCriteria\",\"Outlet\",\"SalesOrderCreated\",\"Awaitting_For_Collection\",\"Duration\"]]\n",
    "Morethan30min=Morethan30mins[Morethan30mins.Duration>30]\n",
    "        \n",
    "with pd.ExcelWriter(r\"C:\\Users\\HP\\Documents\\Master\\Reports\\Wairimu Mathenge\\Glazing Branches\\TookMorethan30mins_GlazingReport.xlsx\", engine='xlsxwriter') as writer:    \n",
    "        for group, dataframe in Morethan30min.groupby('Outlet'):\n",
    "            # save the dataframe for each group to a csv\n",
    "            dataframe = dataframe.drop([\"Outlet\"],axis=1)\n",
    "            name = f'{group}'\n",
    "            dataframe.to_excel(writer,sheet_name=name, index=False)\n",
    "            \n",
    "writer.save()\n",
    "\n",
    "def save_xls(list_dfs, xls_path):\n",
    "    with ExcelWriter(xls_path) as writer:\n",
    "        for n, df in enumerate(list_dfs):\n",
    "            df.to_excel(writer,'sheet%s' % n)\n",
    "        writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0db8f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
